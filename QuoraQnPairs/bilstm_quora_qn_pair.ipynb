{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Reshape, Embedding,Bidirectional, LSTM, Dropout, Flatten,concatenate, Dense, BatchNormalization, Lambda, TimeDistributed, Dot, dot\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404346</th>\n",
       "      <td>404346</td>\n",
       "      <td>789792</td>\n",
       "      <td>789793</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404347</th>\n",
       "      <td>404347</td>\n",
       "      <td>789794</td>\n",
       "      <td>789795</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404348</th>\n",
       "      <td>404348</td>\n",
       "      <td>789796</td>\n",
       "      <td>789797</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404349</th>\n",
       "      <td>404349</td>\n",
       "      <td>789798</td>\n",
       "      <td>789799</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404350</th>\n",
       "      <td>404350</td>\n",
       "      <td>789800</td>\n",
       "      <td>789801</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404351 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404346  404346  789792  789793   \n",
       "404347  404347  789794  789795   \n",
       "404348  404348  789796  789797   \n",
       "404349  404349  789798  789799   \n",
       "404350  404350  789800  789801   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404346  How many keywords are there in the Racket prog...   \n",
       "404347          Do you believe there is life after death?   \n",
       "404348                                  What is one coin?   \n",
       "404349  What is the approx annual cost of living while...   \n",
       "404350              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404346  How many keywords are there in PERL Programmin...             0  \n",
       "404347         Is it true that there is life after death?             1  \n",
       "404348                                  What's this coin?             0  \n",
       "404349  I am having little hairfall problem but I want...             0  \n",
       "404350      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404351 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"/home/sagar24/nlp_dataset/quora/archive/questions.csv\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404351.000000</td>\n",
       "      <td>404351.000000</td>\n",
       "      <td>404351.000000</td>\n",
       "      <td>404351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202175.000000</td>\n",
       "      <td>391840.987691</td>\n",
       "      <td>390195.973765</td>\n",
       "      <td>0.369248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116726.223686</td>\n",
       "      <td>228430.857607</td>\n",
       "      <td>228803.645742</td>\n",
       "      <td>0.482602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101087.500000</td>\n",
       "      <td>193381.000000</td>\n",
       "      <td>191012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202175.000000</td>\n",
       "      <td>390630.000000</td>\n",
       "      <td>388364.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303262.500000</td>\n",
       "      <td>589514.000000</td>\n",
       "      <td>588071.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404350.000000</td>\n",
       "      <td>789800.000000</td>\n",
       "      <td>789801.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1           qid2   is_duplicate\n",
       "count  404351.000000  404351.000000  404351.000000  404351.000000\n",
       "mean   202175.000000  391840.987691  390195.973765       0.369248\n",
       "std    116726.223686  228430.857607  228803.645742       0.482602\n",
       "min         0.000000       1.000000       2.000000       0.000000\n",
       "25%    101087.500000  193381.000000  191012.000000       0.000000\n",
       "50%    202175.000000  390630.000000  388364.000000       0.000000\n",
       "75%    303262.500000  589514.000000  588071.000000       1.000000\n",
       "max    404350.000000  789800.000000  789801.000000       1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy = train_dataset.copy()\n",
    "train_df_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149306.000000</td>\n",
       "      <td>149306.000000</td>\n",
       "      <td>149306.000000</td>\n",
       "      <td>149306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200837.169457</td>\n",
       "      <td>391048.269266</td>\n",
       "      <td>390776.485078</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116197.758898</td>\n",
       "      <td>227527.280271</td>\n",
       "      <td>227507.463550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100183.000000</td>\n",
       "      <td>193421.000000</td>\n",
       "      <td>193116.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200479.500000</td>\n",
       "      <td>390273.000000</td>\n",
       "      <td>389638.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>301292.750000</td>\n",
       "      <td>587967.000000</td>\n",
       "      <td>587675.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404347.000000</td>\n",
       "      <td>789794.000000</td>\n",
       "      <td>789795.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1           qid2  is_duplicate\n",
       "count  149306.000000  149306.000000  149306.000000      149306.0\n",
       "mean   200837.169457  391048.269266  390776.485078           1.0\n",
       "std    116197.758898  227527.280271  227507.463550           0.0\n",
       "min         5.000000      11.000000      12.000000           1.0\n",
       "25%    100183.000000  193421.000000  193116.000000           1.0\n",
       "50%    200479.500000  390273.000000  389638.500000           1.0\n",
       "75%    301292.750000  587967.000000  587675.000000           1.0\n",
       "max    404347.000000  789794.000000  789795.000000           1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy[train_df_copy['is_duplicate'] > 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148487"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_copy[train_df_copy['is_duplicate'] > 0]['qid1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_copy['qid1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537388"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_set = set(train_df['question1'].unique())\n",
    "q2_set = set(train_df['question2'].unique())\n",
    "all_ques_list = q1_set | q2_set\n",
    "len(all_ques_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india? : What is the step by step guide to invest in share market? : 0\n"
     ]
    }
   ],
   "source": [
    "q1_list = train_df['question1'].tolist()\n",
    "q1_list = [str(ques) for ques in q1_list]\n",
    "q2_list = train_df['question2'].tolist()\n",
    "q2_list = [str(ques) for ques in q2_list]\n",
    "is_duplicate_list = train_df['is_duplicate'].tolist()\n",
    "\n",
    "print(q1_list[0],\":\",q2_list[0],\":\",is_duplicate_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 95603\n"
     ]
    }
   ],
   "source": [
    "all_questions_list = q1_list + q2_list\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(all_questions_list)\n",
    "\n",
    "q1_word_seq = tokenizer.texts_to_sequences(q1_list)\n",
    "q2_word_seq = tokenizer.texts_to_sequences(q2_list)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer word index we've gotten for later\n",
    "\n",
    "dictionary = word_index\n",
    "# Let's save this out so we can use it later\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 400000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "with open(expanduser('/home/sagar24/nlp codes/8542_11957_compressed_glove.6B.50d.txt/glove.6B.50d.txt'), encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 35261\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 100000\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404351, 70)\n",
      "Shape of question2 data tensor: (404351, 70)\n",
      "Shape of label tensor: (404351,)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 70\n",
    "#to reduce training time\n",
    "q1_data = pad_sequences(q1_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(q2_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(is_duplicate_list, dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404351, 2, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323480, 70)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "Q1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import add\n",
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "q1 = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), merge_mode=\"sum\")(q1)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "q2 = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), merge_mode=\"sum\")(q2)\n",
    "\n",
    "attention = dot([q1,q2], [1,1])\n",
    "attention = Flatten()(attention)\n",
    "attention = Dense((MAX_SEQUENCE_LENGTH*EMBEDDING_DIM))(attention)\n",
    "attention = Reshape((MAX_SEQUENCE_LENGTH, EMBEDDING_DIM))(attention)\n",
    "DROPOUT=0.2\n",
    "merged = add([q1,attention])\n",
    "merged = Flatten()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 70, 50)       4780200     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 70, 50)       4780200     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 70, 50)       40400       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 70, 50)       40400       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 50, 50)       0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2500)         0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3500)         8753500     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 70, 50)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 70, 50)       0           bidirectional_2[0][0]            \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3500)         0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          700200      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 200)          40200       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200)          800         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 200)          40200       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 200)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200)          800         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 200)          40200       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 200)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 200)          800         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            201         batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 19,218,901\n",
      "Trainable params: 9,656,901\n",
      "Non-trainable params: 9,562,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2021-07-02 13:08:32.100073\n",
      "Epoch 1/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.6878WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 365s 578ms/step - loss: 0.5806 - accuracy: 0.6878 - val_loss: 0.5156 - val_accuracy: 0.7395\n",
      "Epoch 2/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.7511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 572ms/step - loss: 0.4877 - accuracy: 0.7511 - val_loss: 0.4954 - val_accuracy: 0.7445\n",
      "Epoch 3/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.7715WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 360s 570ms/step - loss: 0.4552 - accuracy: 0.7715 - val_loss: 0.4520 - val_accuracy: 0.7764\n",
      "Epoch 4/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.7867WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 360s 570ms/step - loss: 0.4315 - accuracy: 0.7867 - val_loss: 0.4460 - val_accuracy: 0.7792\n",
      "Epoch 5/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.4128 - accuracy: 0.7983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 360s 570ms/step - loss: 0.4128 - accuracy: 0.7983 - val_loss: 0.4281 - val_accuracy: 0.7906\n",
      "Epoch 6/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8100WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 361s 572ms/step - loss: 0.3942 - accuracy: 0.8100 - val_loss: 0.4260 - val_accuracy: 0.7902\n",
      "Epoch 7/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8200WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 361s 572ms/step - loss: 0.3774 - accuracy: 0.8200 - val_loss: 0.4236 - val_accuracy: 0.7959\n",
      "Epoch 8/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8308WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 361s 571ms/step - loss: 0.3608 - accuracy: 0.8308 - val_loss: 0.4195 - val_accuracy: 0.8003\n",
      "Epoch 9/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8411WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 361s 571ms/step - loss: 0.3441 - accuracy: 0.8411 - val_loss: 0.4273 - val_accuracy: 0.7993\n",
      "Epoch 10/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8498WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 366s 579ms/step - loss: 0.3278 - accuracy: 0.8498 - val_loss: 0.4336 - val_accuracy: 0.8015\n",
      "Epoch 11/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8587WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 368s 583ms/step - loss: 0.3117 - accuracy: 0.8587 - val_loss: 0.4346 - val_accuracy: 0.7970\n",
      "Epoch 12/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 573ms/step - loss: 0.2962 - accuracy: 0.8671 - val_loss: 0.4424 - val_accuracy: 0.8026\n",
      "Epoch 13/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8744WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 360s 570ms/step - loss: 0.2820 - accuracy: 0.8744 - val_loss: 0.4456 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 359s 568ms/step - loss: 0.2670 - accuracy: 0.8823 - val_loss: 0.4484 - val_accuracy: 0.7999\n",
      "Epoch 15/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.8890WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 573ms/step - loss: 0.2529 - accuracy: 0.8890 - val_loss: 0.4507 - val_accuracy: 0.8044\n",
      "Epoch 16/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.8963WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 573ms/step - loss: 0.2394 - accuracy: 0.8963 - val_loss: 0.4876 - val_accuracy: 0.7980\n",
      "Epoch 17/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9032WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 573ms/step - loss: 0.2249 - accuracy: 0.9032 - val_loss: 0.4891 - val_accuracy: 0.8022\n",
      "Epoch 18/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.9085WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 573ms/step - loss: 0.2134 - accuracy: 0.9085 - val_loss: 0.5069 - val_accuracy: 0.8006\n",
      "Epoch 19/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9148WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 362s 572ms/step - loss: 0.2016 - accuracy: 0.9148 - val_loss: 0.5086 - val_accuracy: 0.8021\n",
      "Epoch 20/20\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9180WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "632/632 [==============================] - 379s 600ms/step - loss: 0.1927 - accuracy: 0.9180 - val_loss: 0.5092 - val_accuracy: 0.8043\n",
      "Training ended at 2021-07-02 15:10:17.658848\n",
      "Minutes elapsed: 121.759306\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint('question_pairs_weights_type1_final_new.h5', monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    validation_data=([Q1_test, Q2_test], y_test),\n",
    "                    verbose=1,\n",
    "                    batch_size=512,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('quo_qn_pair_bilstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#for testing :\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def convert_text_to_index_array(text, dictionary):\n",
    "    words = text_to_word_sequence(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "        else:\n",
    "            print(\"'%s' not in training corpus; ignoring.\" %(word))\n",
    "    return wordIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.878805]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question1 = \"When was the company formed?\"\n",
    "question2 = \"When is the company anniversary?\"\n",
    "\n",
    "q1_word_seq = convert_text_to_index_array(question1,dictionary)\n",
    "q1_word_seq = [q1_word_seq]\n",
    "q2_word_seq = convert_text_to_index_array(question2,dictionary)\n",
    "q2_word_seq = [q2_word_seq]\n",
    "q1_data = pad_sequences(q1_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(q2_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "pred = model.predict([q1_data,q2_data])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26883698]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question1 = \"What is a dog?\"\n",
    "question2 = \"What is a cat?\"\n",
    "\n",
    "q1_word_seq = convert_text_to_index_array(question1,dictionary)\n",
    "q1_word_seq = [q1_word_seq]\n",
    "q2_word_seq = convert_text_to_index_array(question2,dictionary)\n",
    "q2_word_seq = [q2_word_seq]\n",
    "q1_data = pad_sequences(q1_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(q2_word_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "pred = model.predict([q1_data,q2_data])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
