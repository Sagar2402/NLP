{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    words=[]\n",
    "    with open(file_name) as f:\n",
    "        file_name_data = f.read()\n",
    "    file_name_data=file_name_data.lower()\n",
    "    words = re.findall('\\w+',file_name_data)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(data):\n",
    "    word_count_dict = {}\n",
    "    word_count_dict = Counter(data)        \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    probs = {}\n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique words in Vocab : 6116 \n"
     ]
    }
   ],
   "source": [
    "data = process_data('/home/sagar24/nlp codes/shakespeare.txt')\n",
    "vocab = set(data)  \n",
    "word_count_dict = get_count(data)\n",
    "print(f\"# Unique words in Vocab : {len(vocab)} \")\n",
    "probs = get_probs(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append((word[:c],word[c:]))\n",
    "    for a,b in split_l:\n",
    "        delete_l.append(a+b[1:])\n",
    "    #print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "    return delete_l\n",
    "\n",
    "def switch_letter(word): \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    len_word=len(word)\n",
    "    for c in range(len_word):\n",
    "        split_l.append((word[:c],word[c:]))\n",
    "    switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >= 2]\n",
    "    #print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    return switch_l\n",
    "\n",
    "def replace_letter(word, verbose=False):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append((word[0:c],word[c:]))\n",
    "    replace_l = [a + l + (b[1:] if len(b)> 1 else '') for a,b in split_l if b for l in letters]\n",
    "    replace_set=set(replace_l)    \n",
    "    replace_set.remove(word)\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    #print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    return replace_l\n",
    "\n",
    "def insert_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)+1):\n",
    "        split_l.append((word[0:c],word[c:]))\n",
    "    insert_l = [ a + l + b for a,b in split_l for l in letters]\n",
    "    #print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    edit_one_set = set()\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    if allow_switches:\n",
    "        edit_one_set.update(switch_letter(word))\n",
    "    edit_one_set.update(replace_letter(word))\n",
    "    edit_one_set.update(insert_letter(word))\n",
    "    return edit_one_set\n",
    "\n",
    "def edit_two_letters(word, allow_switches = True):\n",
    "    edit_two_set = set()\n",
    "    edit_one = edit_one_letter(word,allow_switches=allow_switches)\n",
    "    for w in edit_one:\n",
    "        if w:\n",
    "            edit_two = edit_one_letter(w,allow_switches=allow_switches)\n",
    "            edit_two_set.update(edit_two)\n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab))\n",
    "    n_best = [[s,probs[s]] for s in list(reversed(suggestions))]\n",
    "    print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  shakespare \n",
      "suggestions =  ['shakespeare']\n",
      "word 0: shakespeare, probability 0.000168\n"
     ]
    }
   ],
   "source": [
    "my_word = 'shakespare' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2)\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  cerriage \n",
      "suggestions =  ['carriage']\n",
      "word 0: carriage, probability 0.000019\n"
     ]
    }
   ],
   "source": [
    "my_word = 'cerriage' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2)\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    for row in range(1,m+1): \n",
    "        D[row,0] = D[row-1,0] + del_cost\n",
    "        \n",
    "    for col in range(1,n+1): \n",
    "        D[0,col] = D[0,col-1] + ins_cost\n",
    "        \n",
    "    for row in range(1,m+1): \n",
    "        for col in range(1,n+1):\n",
    "            r_cost = rep_cost\n",
    "            if source[row-1] == target[col-1]:\n",
    "                r_cost = 0    \n",
    "            D[row,col] = min([D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost])\n",
    "    med = D[m,n]\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=\"favore\"\n",
    "targets = edit_one_letter(w1,allow_switches = False)\n",
    "for t in targets:\n",
    "    _, min_edits = min_edit_distance(w1, t,1,1,1)  \n",
    "    if min_edits != 1: \n",
    "        print(w1, t, min_edits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "favore favore 0\n"
     ]
    }
   ],
   "source": [
    "w1=\"favore\"\n",
    "targets = edit_two_letters(w1,allow_switches = False)  \n",
    "for t in targets:\n",
    "    _, min_edits = min_edit_distance(w1, t,1,1,1)  \n",
    "    if min_edits != 2 and min_edits != 1: \n",
    "        print(w1, t, min_edits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
